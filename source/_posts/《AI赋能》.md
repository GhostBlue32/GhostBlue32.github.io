---
title: '[[《AI赋能》]]'
date: '2025-06-09'
tags:
- 里德
- 格雷格
- 未来
- AI
- 公地悲剧
- 政府
- 自由
- 迭代
---
#里德·霍夫曼 #格雷格·贝亚托

## 总结
### 名词
1. **人类能动性**：主要含义是作为个体，你有能力做出选择、独立行动，从而影响自己的生活。
2. **消费者盈余**：人们为产品或服务支付的价格与其对该产品或服务的估值之间的差额。

### 未来观点
作者将对于AI的态度从否定到肯定，根据程度进行分类，分别是末日论者、悲观论者、乐观论者和繁荣论者，并将自己归纳为繁荣论者——相信AI在无数领域加速人类的进步，并且呼吁所有人都加入AI的开发和部署中。总体上持特别乐观的态度，以至于很少有相反的观点进行对比。我同意霍夫曼对于AI能够增强对于数据的利用，AI未来的能力还是有所怀疑。作者支持技术自下而上发展，反对自上而下的规划，并且呼吁用户主动参与到这个发展进程当中去。

对于技术，霍夫曼认为：
1. 如果一项技术有可能被创造出来，人类就会毫无疑义地创造它，并且技术能够定义、重新定义、加深并扩展我们作为人类的意义。
2. 发起新技术之后，无法完全掌控，新技术会产生自己的引力。
3. 起初看似有明显缺陷，甚至被认为非人性化的技术，最终往往会被证明对人类大有裨益。（GPS作为其中一例）
4. 随着新技术逐渐融入社会，新的法规和规范也应运而生，这些变革不断塑造着我们对自由的认知。

对于信息和网络，作者的观点有：
1. 使用AI进行大量的数据分析，带来更加个性化的定制。聚合和分析大量消费者数据的新能力使制造商、营销人员和内容创作者能够细分市场，针对更精细的人口统计，服务于特定的亚文化、生活方式和兴趣。
2. 数字平台上，即使广泛地使用它，也不会降低他人的使用能力。数据是非竞争性的，并且会不断增长，不会产生公地悲剧。
3. 网络世界中，强大的公共身份也能创造自主性和能动性。我们渴望公共身份所带来的认可、接纳和个人主权。
4. 处于信息爆炸的时代，人们利用的信息占信息总量的百分比很低。使用AI，我们就能有效地利用我们所产生的数据和信息，将“大数据”转化为”大知识“，从而在几乎所有领域增强我们的能动性。

对于AI发展的路径，作者的路径可以总结为**迭代部署**：
1. 吸纳不同公众进行广泛参与，并持续收集公众的反馈。
2. 塑造公众对于AI的信念、规范和共同价值观也同样重要。
3. 与GPS对比，GPS的输出是确定的，而如今AI训练的语料是不确定的，输出也是不确定的，结果更容易被用户进行影响。
4. 大语言模型的逐步互动功能可以促使用户高度参与，有助于减少其偏见、有害信息输出，用户向大语言模型提供的关于自身定位的信息越详尽，越能精准规划前行路径。
5. 在互联网创建的新世界中，表达赞同或反对的方式比以往任何时候都更加强大和去中心化，也更透明。公众应该利用互联网平台，表达自己的观点，促成集体价值观和现实操作转化为正式法规，这也有利于法规的执行。

### 未来设想
“监管2.0”式未来：用户在这种模式下，通过集体表达自己的偏好和判断来激励AI持续发展，并且通过模型的透明度建立信任。用户可以很好地通过模型数据得知模型信息的准确率，从而判断在什么时候使用哪种模型。开发者也有动力以对用户有意义的方式来改进他们的模型。

在**心理健康**方面，AI可能开创一个更加全面、持续且深度融入日常生活的心理健康护理新时代。让心理治疗像安全带一样成为日常生活中重要的一部分。

**动态契约**：包含机器学习算法，可以不断从它收集到的数据中进行学习、进化、完善。代码合约相较于人类撰写的合约和法律可以展现出更高的灵活性和适应性。

**自由**：自由本质上是一种关系。自由并非一个独立于环境之外的永恒原则，而是始终在变化。我们对自由的构想，往往与当时技术能实现或不能实现的能力紧密相关。

**政府**：应利用AI将公众与立法过程更紧密地连接起来。通过使用AI创造新的机会来发挥公众在政策制定中的作用，可以使社会制度更具协作性和参与性。通过公众与政府在线上紧密相连，AI可以成为提高社会凝聚力和弥合分歧的建设性力量。集体决策平台将每个人都视为可进行深入互动的潜在伙伴。总体上增强人类的能动性。

### 其他观点
1. 我们往往觉得监管者和企业家是相互对立的。但事实上，他们有共同的目标：改进世界的某个方面。监管者通过立法来实现，而企业家则通过创新产品和服务来达成。

### 批判
1. Hoffman 描绘的“用户众包纠偏”需要高透明度 API、模型可复现度，但大厂当前大多视权重与训练数据为商业机密。
2. 数据所有权难以定义：多数司法体系并不把个人数据当成“可排他占有的物权”，而是用“隐私/人格权”去规制。个人拥有的是控制权（consent, portability, erasure）而非处分权（转让、抵押）。
3. 数据复利能力强，导致平台垄断加速，用户退出困难。巨头还会以“合规成本高”为由，反对数据可携带、接口开放，结果把合规变成护城河。

#未来 #AI #公地悲剧 #政府 #自由 #迭代 

---
### 译者序言
超级能动性（Superagency），是指在AI技术的赋能之下，个体和集体能够突破限制，实现潜能的最大化发挥。它不仅代表了个体能力的提升，更强调这种提升如何在社会层面产生累积效应，使得每个人都能受益，并有机会成为更好的自己。

面对不确定性，创业者精神比预测未来更重要。阻止一个不想要的未来的最可靠方式，不是试图踩下创新的刹车或停滞不前，而是引导自己驶向更加光明的明天。

### 前言
我们从数千年的经验中了解到，如果一项技术有可能被创造出来，人类就会毫无疑义地创造它。我们发明的每一项新技术——从语言到书籍，再到移动电话，都在定义、重新定义、加深并扩展我们作为人类的意义。我们是这个过程的发起者，但我们无法完全控制它。一旦启动，新技术就会产生自身的引力。

未来并不是专家和监管者可以精心设计的东西，而是一个由整个社会共同探索和发现的过程。

那些起初看似有明显缺陷，甚至被认为非人性化的技术，最终往往会被证明对人类大有裨益。

### AI焦虑时代，超级能动性让我们找回人生主动权
人的能动性是哲学、社会学和心理学中的一个基本概念。它的主要含义是，作为个体，你有能力做出选择、独立行动，从而影响自己的生活。

> [!info] AI在增强人类的能动性，因为它在帮助你采取旨在实现你期望结果的行动。
> 人类的历史就是人类的智慧和自然的能源协同作用，激发人类的能动性，进而推动人类进步。无论对于个体还是集体，我们能够利用的智慧和能源越多，我们实现目标的能力就越强。

对于AI的态度：
1. 末日论者：末日论者认为我们正走向一个糟糕的未来，最坏的情况是，超级智能、完全自主的AI可能不再与人类价值观保持一致，甚至可能决定彻底毁灭人类。
2. 悲观论者：悲观论者既对AI持强烈的批评态度，也对末日论者严厉指责。
	1. 人们真正应该优先关注的是更近期的关于AI风险和危害的问题，如失业风险的增加、虚假信息的泛滥、现有系统性偏见的放大以及个体能动性被削弱。
	2. 悲观论者支持运用具有限制性的、自上而下的管理方式，认为AI的开发和部署应该由官方监管，发布和运行应由监督机构严格监测和控制。
3. 乐观论者：AI带来的革新和生产力的提升等积极影响将远远超过其产生的任何负面影响。他们主张给予开发者足够的空间，按其认为合适的方式来构建AI，并利用AI在最短时间内产生最佳的结果。
4. 繁荣论者：他们相信AI可以在无数领域加速人类进步。倡导在现实条件允许的情况下用户能广泛参与AI的开发和部署，这正是迭代部署的意义。

作者将自己归类为繁荣论者：
1. 要想以民主、负责任、合乎伦理且高效的方式开发AI，我们必须吸纳不同公众的广泛参与，并持续收集公众的反馈。
2. 关键问题是**信任**：更强大的模型所引发的文化冲突会进一步加剧，人们对AI预先进行监管甚至禁止的意愿将变得更加强烈。仅仅制定关于AI的规则是不够的，信念、规范和共同价值观也同样重要。

### 关注而非监控
聚合和分析大量消费者数据的新能力使制造商、营销人员和内容创作者能够细分市场，针对更精细的人口统计，服务于特定的亚文化、生活方式和兴趣。在众多领域，个性化和定制化开始取代20世纪工业化时代标准化的一刀切做法。过去60年来的历史一再表明，信息的广泛共享、收集、分析和多样化应用，可以极大地赋能和提升个体。

在网络世界中，强大的公共身份也能创造自主性和能动性。即使我们有时会通过使用假名、虚拟专用网络和加密来寻求躲避数字生活中不断的信息泄露，我们仍然渴望公共身份所带来的认可、接纳和个人主权。

> [!example] 领英平台
> 对作者来说，领英的本质一直是利用网络来以新的方式分享和发现信息，通过身份来增加信任。为了使这种新型信任平台发挥作用，我们必须说服人们分享比他们习惯在网上分享的更多信息。虽然也有对隐私的保护，但是至少要让自己在直接联系人之外的其他领英会员面前部分可见，以便促成新的联系。每个人现在可以掌控自己的个人身份，展现希望他人知道的信息，定义自己。

社会的发展依赖信息的自由流动，至少和它依赖隐私一样重要。越多地拥抱AI，我们就越能有效地利用我们所产生的数据和信息，从而在几乎所有领域增强我们的能动性。

如今的信息爆炸，人们利用的信息占信息总量的百分比极低。AI可以利用这些数量巨大的知识。将“大数据”转化为“大知识”，从而实现数据驱动的清晰度和增长的“新光明时代”。当那些沉睡的、未被充分利用或仅在特定背景下有意义的数据，被重新利用、合成并以新颖且具有复合效应的方式转化时，就不是一种掠夺，而是一种对资源的有效利用与再创造。

> [!question] 庞大的数据？
> 对于这么多庞大的数据，作者竟然以数据的总量来对比居民能够利用到的数据量。对于信息的质量没有考量。

尽管AI模型没有意识或自我意识，但它们常以统计上最优的方式，表现出超越人类常规水平的善意和同理心。AI可能开创一个更加全面、持续且深度融入日常生活的心理健康护理新时代。让心理治疗像安全带一样成为日常生活中重要的一部分。

### 消费者盈余
经济学家将人们为产品或服务支付的价格与其对该产品或服务的估值之间的差额称为“消费者盈余”。当一种产品或服务免费时，只要消费者对其赋予一定价值，消费者盈余同样可以存在。人们愿意放弃使用搜索引擎一年所需的中位数补偿金高达17530美元；对于电子邮件，这一金额是8414美元；对于数字地图，这一金额则是3648美元。

数字平台上，即使广泛地使用它，也不会降低他人的使用能力。数据是非竞争性的，并且会不断增长，不会产生公地悲剧。

如今，推动大部分私人公地运作的基本契约，是用户获得免费服务，作为交换，平台运营商获得对用户生成数据的访问权限。

在数据日益丰富的世界中，消费者最终愿意为之付费的往往不是数据本身，而是能让数据易于被发现和批量访问的机制。

将数据视为一种准公共物品，积极地共享、聚合并以创新的方式应用，有可能创造出用户从中获得的价值远远超过平台运营商自身获取的价值的服务。

私人公地通过让知识和机会更公平地被获取，增强了个体能动性、教育机会公平性、社会流动性，并最终促进了职业成长。

### 测试
虽然测试和监管的目标都是标准化与可控制，但测试将关注点从合规性提升到了持续改进上。这是一种游戏化的监管。

如果你的主要意图是切实采用AI，而非禁止AI，那么模型如何执行固然重要，但更重要的是它做了什么。

逐渐实现民主化和草根治理的“监管2.0”式未来：用户在这种模式下，通过集体表达自己的偏好和判断来激励AI持续发展，并且通过模型的透明度建立信任。如果用户可以很容易地知道某个模型在提供医疗建议时有3%的概率生成错误信息，他们就可以更明智地决定在不同任务中应更信任哪些模型。与此同时，开发者也会有强大的动力，以真正对用户有意义的方式改进他们的模型。

我们往往觉得监管者和企业家是相互对立的。但事实上，他们有共同的目标：改进世界的某个方面。监管者通过立法来实现，而企业家则通过创新产品和服务来达成。

新能力总是伴随着新风险。但我们不应盲目追求零风险，而应致力于理解现实环境中的风险，并有条不紊地努力管控和降低这些风险。**迭代部署**便是实现这一目标的有效途径。


### AI与GPS
作者将AI与GPS进行类比，指出GPS在此前曾经被美国政府限制发展，虽然这项技术也会将司机导入偏远地区或者水域，但是GPS在全球范围内每时每刻、周而复始地为人们提供着大量有益的服务。GPS的“训练语料”是地图，是确定性的，但是如今AI的训练语料是不确定的，输出也是不确定的，结果可以由用户影响。

ChatGPT最初之所以具有变革性，很大程度上是因为它明确要求用户在使用过程中持续发挥作用。大语言模型的这种逐步互动功能可以促使用户高度参与，有助于减少其偏见、有害信息输出，用户向大语言模型提供的关于自身定位的信息越详尽，越能精准规划前行路径。

“AI使用经验较少的员工将从大语言模型的使用中受益更多。”


### 动态契约
编写包含机器学习算法的合约，可在一定程度上使其接近由人类管理的传统法律和合同所具有的灵活性。同时，只要系统能够从它们收集或接收到的数据中学习，就能不断进化、完善规则，代码合约相较于人类撰写的合约和法律可以展现出更高的灵活性和适应性。

我们在禁止停车区遵守规定、缴纳所得税、遵守禁烟区规定，以及遵循广泛的文化规范和行为准则时，我们实际上是在参与一个更宏大的社会契约。这些系统的有效运作，依赖于我们的自愿遵守，而非强制执行。法律和社会规范虽提供了框架，但公众的接受程度才是其真正的生命力所在。法律和规范之所以有效，源于我们的选择和认同。它们的一个重要功能，是将政体塑造为围绕一套共同规则和价值观自愿团结起来的成员集合。

在互联网创建的新世界中，表达赞同或反对的方式比以往任何时候都更加强大和去中心化，也更透明。这种情况不仅会影响集体价值观和现实操作如何转化为正式法规，还将决定人们和社区如何负责地遵守这些法规。为了使AI安全且有效地融入社会，公众就必须在AI的合法化过程中发挥积极和实质性的作用。


### 自由
自由本质上是一种关系。自由并非一个独立于环境之外的永恒原则，而是始终在变化。我们对自由的构想，往往与当时技术能实现或不能实现的能力紧密相关。享有自由可能是因为难以被监管，比如说复制盒式磁带；也有可能是实施困难，比如CRISPR工具问世前，基因工程几乎不受法律约束。

随着新技术逐渐融入社会，新的法规和规范也应运而生，这些变革不断塑造着我们对自由的认知。印刷术问世前，只有天主教会和大学制定的书籍标准和禁令，未上升到法律，如今有更多的对于书籍的审查性法律，但新的监管环境并没有旧的那般限制言论自由。

未来：政府应利用AI将公众与立法过程更紧密地连接起来，而非将AI首先视为一种可通过面部识别、预测性警务和算法监控等应用实现指挥和控制治理的机制。通过使用AI创造新的机会来发挥公众在政策制定中的作用，可以使社会制度更具协作性和参与性，同时还可缓解长期以来人们对AI可能助长专制主义的担忧。

通过将公众与政府在线上紧密相连，AI可以成为提高社会凝聚力和弥合分歧的建设性力量。集体决策平台将每个人都视为可进行深入互动的潜在伙伴。这些平台将构建一个技术增强人类能动性而非取代人类的世界。

### 导读
人类与技术自始至终都是一种共生的关系、一种相乘的关系，而不是一种简单的叠加关系。
